{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv (r'C:\\Users\\Sharon & Floyd\\Downloads\\AI files\\Capstone\\Financial\\train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38355.0</td>\n",
       "      <td>1.043949</td>\n",
       "      <td>0.318555</td>\n",
       "      <td>1.045810</td>\n",
       "      <td>2.805989</td>\n",
       "      <td>-0.561113</td>\n",
       "      <td>-0.367956</td>\n",
       "      <td>0.032736</td>\n",
       "      <td>-0.042333</td>\n",
       "      <td>-0.322674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240105</td>\n",
       "      <td>-0.680315</td>\n",
       "      <td>0.085328</td>\n",
       "      <td>0.684812</td>\n",
       "      <td>0.318620</td>\n",
       "      <td>-0.204963</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.037894</td>\n",
       "      <td>49.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22555.0</td>\n",
       "      <td>-1.665159</td>\n",
       "      <td>0.808440</td>\n",
       "      <td>1.805627</td>\n",
       "      <td>1.903416</td>\n",
       "      <td>-0.821627</td>\n",
       "      <td>0.934790</td>\n",
       "      <td>-0.824802</td>\n",
       "      <td>0.975890</td>\n",
       "      <td>1.747469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335332</td>\n",
       "      <td>-0.510994</td>\n",
       "      <td>0.035839</td>\n",
       "      <td>0.147565</td>\n",
       "      <td>-0.529358</td>\n",
       "      <td>-0.566950</td>\n",
       "      <td>-0.595998</td>\n",
       "      <td>-0.220086</td>\n",
       "      <td>16.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2431.0</td>\n",
       "      <td>-0.324096</td>\n",
       "      <td>0.601836</td>\n",
       "      <td>0.865329</td>\n",
       "      <td>-2.138000</td>\n",
       "      <td>0.294663</td>\n",
       "      <td>-1.251553</td>\n",
       "      <td>1.072114</td>\n",
       "      <td>-0.334896</td>\n",
       "      <td>1.071268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>0.352856</td>\n",
       "      <td>-0.341505</td>\n",
       "      <td>-0.145791</td>\n",
       "      <td>0.094194</td>\n",
       "      <td>-0.804026</td>\n",
       "      <td>0.229428</td>\n",
       "      <td>-0.021623</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86773.0</td>\n",
       "      <td>-0.258270</td>\n",
       "      <td>1.217501</td>\n",
       "      <td>-0.585348</td>\n",
       "      <td>-0.875347</td>\n",
       "      <td>1.222481</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>1.073860</td>\n",
       "      <td>-0.161408</td>\n",
       "      <td>0.200665</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424626</td>\n",
       "      <td>-0.781158</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.178614</td>\n",
       "      <td>-0.315616</td>\n",
       "      <td>0.096665</td>\n",
       "      <td>0.269740</td>\n",
       "      <td>-0.020635</td>\n",
       "      <td>10.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127202.0</td>\n",
       "      <td>2.142162</td>\n",
       "      <td>-0.494988</td>\n",
       "      <td>-1.936511</td>\n",
       "      <td>-0.818288</td>\n",
       "      <td>-0.025213</td>\n",
       "      <td>-1.027245</td>\n",
       "      <td>-0.151627</td>\n",
       "      <td>-0.305750</td>\n",
       "      <td>-0.869482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010115</td>\n",
       "      <td>0.021722</td>\n",
       "      <td>0.079463</td>\n",
       "      <td>-0.480899</td>\n",
       "      <td>0.023846</td>\n",
       "      <td>-0.279076</td>\n",
       "      <td>-0.030121</td>\n",
       "      <td>-0.043888</td>\n",
       "      <td>39.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   38355.0  1.043949  0.318555  1.045810  2.805989 -0.561113 -0.367956   \n",
       "1   22555.0 -1.665159  0.808440  1.805627  1.903416 -0.821627  0.934790   \n",
       "2    2431.0 -0.324096  0.601836  0.865329 -2.138000  0.294663 -1.251553   \n",
       "3   86773.0 -0.258270  1.217501 -0.585348 -0.875347  1.222481 -0.311027   \n",
       "4  127202.0  2.142162 -0.494988 -1.936511 -0.818288 -0.025213 -1.027245   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.032736 -0.042333 -0.322674  ... -0.240105 -0.680315  0.085328  0.684812   \n",
       "1 -0.824802  0.975890  1.747469  ... -0.335332 -0.510994  0.035839  0.147565   \n",
       "2  1.072114 -0.334896  1.071268  ...  0.012220  0.352856 -0.341505 -0.145791   \n",
       "3  1.073860 -0.161408  0.200665  ... -0.424626 -0.781158  0.019316  0.178614   \n",
       "4 -0.151627 -0.305750 -0.869482  ...  0.010115  0.021722  0.079463 -0.480899   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.318620 -0.204963  0.001662  0.037894   49.67      0  \n",
       "1 -0.529358 -0.566950 -0.595998 -0.220086   16.94      0  \n",
       "2  0.094194 -0.804026  0.229428 -0.021623    1.00      0  \n",
       "3 -0.315616  0.096665  0.269740 -0.020635   10.78      0  \n",
       "4  0.023846 -0.279076 -0.030121 -0.043888   39.96      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    227451\n",
       "1       394\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      94752.853076\n",
       "V1           -0.003321\n",
       "V2           -0.001652\n",
       "V3            0.001066\n",
       "V4           -0.000374\n",
       "V5            0.000877\n",
       "V6            0.000770\n",
       "V7           -0.000035\n",
       "V8            0.001625\n",
       "V9           -0.000391\n",
       "V10          -0.000794\n",
       "V11           0.002083\n",
       "V12           0.000010\n",
       "V13           0.000080\n",
       "V14           0.000928\n",
       "V15          -0.000737\n",
       "V16           0.000433\n",
       "V17          -0.000007\n",
       "V18          -0.000831\n",
       "V19          -0.000191\n",
       "V20           0.000671\n",
       "V21           0.000563\n",
       "V22           0.001234\n",
       "V23          -0.001002\n",
       "V24           0.000254\n",
       "V25           0.000218\n",
       "V26          -0.001128\n",
       "V27          -0.000346\n",
       "V28           0.000498\n",
       "Amount       88.522327\n",
       "Class         0.001729\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      47500.410602\n",
       "V1            1.963028\n",
       "V2            1.661178\n",
       "V3            1.516107\n",
       "V4            1.415061\n",
       "V5            1.367074\n",
       "V6            1.325341\n",
       "V7            1.220384\n",
       "V8            1.192648\n",
       "V9            1.097367\n",
       "V10           1.087268\n",
       "V11           1.021904\n",
       "V12           0.999581\n",
       "V13           0.995449\n",
       "V14           0.959575\n",
       "V15           0.916011\n",
       "V16           0.875795\n",
       "V17           0.851222\n",
       "V18           0.838685\n",
       "V19           0.812614\n",
       "V20           0.772535\n",
       "V21           0.734187\n",
       "V22           0.724544\n",
       "V23           0.625165\n",
       "V24           0.606012\n",
       "V25           0.521348\n",
       "V26           0.482314\n",
       "V27           0.400286\n",
       "V28           0.331184\n",
       "Amount      248.100141\n",
       "Class         0.041548\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x14956bf13d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.Class, data.Amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1495701e6a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.Time, data.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    227451\n",
       "1       394\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data for Time and Amount prior to running analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0.548364\n",
       "V1       -0.003321\n",
       "V2       -0.001652\n",
       "V3        0.001066\n",
       "V4       -0.000374\n",
       "V5        0.000877\n",
       "V6        0.000770\n",
       "V7       -0.000035\n",
       "V8        0.001625\n",
       "V9       -0.000391\n",
       "V10      -0.000794\n",
       "V11       0.002083\n",
       "V12       0.000010\n",
       "V13       0.000080\n",
       "V14       0.000928\n",
       "V15      -0.000737\n",
       "V16       0.000433\n",
       "V17      -0.000007\n",
       "V18      -0.000831\n",
       "V19      -0.000191\n",
       "V20       0.000671\n",
       "V21       0.000563\n",
       "V22       0.001234\n",
       "V23      -0.001002\n",
       "V24       0.000254\n",
       "V25       0.000218\n",
       "V26      -0.001128\n",
       "V27      -0.000346\n",
       "V28       0.000498\n",
       "Amount    0.004503\n",
       "Class     0.001729\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "data.Amount = scale.fit_transform(data[['Amount']])\n",
    "data.Time = scale.fit_transform(data[['Time']])\n",
    "data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.    Use techniques like undersampling or oversampling before running Naïve Bayes, Logistic Regression or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = data.drop(columns='Class')\n",
    "Y_original = data.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    227451\n",
       "1       394\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_original.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 31)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    227451\n",
       "0    227451\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y=smote.fit_resample(X_original,Y_original)\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=0)\n",
    "x_train_original, x_test_original,y_train_original, y_test_original = train_test_split(X_original,Y_original, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318431, 30) (136471, 30) (318431,) (136471,)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159491, 30) (68354, 30) (159491,) (68354,)\n"
     ]
    }
   ],
   "source": [
    "print (x_train_original.shape, x_test_original.shape, y_train_original.shape, y_test_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = GaussianNB()\n",
    "NBO = GaussianNB()\n",
    "NB.fit(x_train, y_train)\n",
    "NBO.fit(x_train_original,y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LRO = LogisticRegression()\n",
    "LR.fit(x_train, y_train)\n",
    "LRO.fit(x_train_original,y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM = svm.SVC(kernel='sigmoid', gamma='auto')\n",
    "# SVM.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Task: Week 2\n",
    "\n",
    "Modeling Techniques:\n",
    "\n",
    "Try out models like Naive Bayes, Logistic Regression or SVM. Find out which one performs the best\n",
    "Use different Tree-based classifiers like Random Forest and XGBoost. \n",
    "       a.    Remember Tree-based classifiers work on two ideologies: Bagging or Boosting\n",
    "       b.    Tree-based classifiers have fine-tuning parameters which takes care of the imbalanced class. Random-Forest and XGBboost.\n",
    "Compare the results of 1 with 2 and check if there is any incremental gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF=RandomForestClassifier()\n",
    "RFO=RandomForestClassifier()\n",
    "XGB=XGBClassifier()\n",
    "XGBO=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.fit(x_train, y_train)\n",
    "RFO.fit(x_train_original,y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:57:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB.fit(x_train, y_train)\n",
    "XGBO.fit(x_train_original,y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes original:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     68236\n",
      "           1       0.06      0.86      0.11       118\n",
      "\n",
      "    accuracy                           0.98     68354\n",
      "   macro avg       0.53      0.92      0.55     68354\n",
      "weighted avg       1.00      0.98      0.99     68354\n",
      "\n",
      "Naive Bayes smote:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92     68376\n",
      "           1       0.97      0.86      0.91     68095\n",
      "\n",
      "    accuracy                           0.92    136471\n",
      "   macro avg       0.92      0.92      0.92    136471\n",
      "weighted avg       0.92      0.92      0.92    136471\n",
      "\n",
      "Logistic Regression original:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     68236\n",
      "           1       0.88      0.63      0.73       118\n",
      "\n",
      "    accuracy                           1.00     68354\n",
      "   macro avg       0.94      0.81      0.87     68354\n",
      "weighted avg       1.00      1.00      1.00     68354\n",
      "\n",
      "Logistic Regression smote:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     68376\n",
      "           1       0.97      0.93      0.95     68095\n",
      "\n",
      "    accuracy                           0.95    136471\n",
      "   macro avg       0.95      0.95      0.95    136471\n",
      "weighted avg       0.95      0.95      0.95    136471\n",
      "\n",
      "random forest original:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     68236\n",
      "           1       0.97      1.00      0.98       118\n",
      "\n",
      "    accuracy                           1.00     68354\n",
      "   macro avg       0.98      1.00      0.99     68354\n",
      "weighted avg       1.00      1.00      1.00     68354\n",
      "\n",
      "random forest smote:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     68376\n",
      "           1       1.00      1.00      1.00     68095\n",
      "\n",
      "    accuracy                           1.00    136471\n",
      "   macro avg       1.00      1.00      1.00    136471\n",
      "weighted avg       1.00      1.00      1.00    136471\n",
      "\n",
      "XGBoost original:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     68236\n",
      "           1       0.91      1.00      0.96       118\n",
      "\n",
      "    accuracy                           1.00     68354\n",
      "   macro avg       0.96      1.00      0.98     68354\n",
      "weighted avg       1.00      1.00      1.00     68354\n",
      "\n",
      "XGBoost smote:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     68376\n",
      "           1       1.00      1.00      1.00     68095\n",
      "\n",
      "    accuracy                           1.00    136471\n",
      "   macro avg       1.00      1.00      1.00    136471\n",
      "weighted avg       1.00      1.00      1.00    136471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Naive Bayes original:\\n',classification_report(y_test_original,NBO.predict(x_test_original)))\n",
    "print ('Naive Bayes smote:\\n',classification_report(y_test,NB.predict(x_test)))\n",
    "print ('Logistic Regression original:\\n',classification_report(y_test_original,LRO.predict(x_test_original)))\n",
    "print ('Logistic Regression smote:\\n',classification_report(y_test,LR.predict(x_test)))\n",
    "print ('random forest original:',classification_report(y_test_original,RF.predict(x_test_original)))\n",
    "print ('random forest smote:',classification_report(y_test,RF.predict(x_test)))\n",
    "print ('XGBoost original:',classification_report(y_test_original,XGB.predict(x_test_original)))\n",
    "print ('XGBoost smote:',classification_report(y_test,XGB.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Task: Week 3\n",
    "\n",
    "Applying ANN:\n",
    "\n",
    "Use ANN (Artificial Neural Network) to identify fradulent and non-fradulent.\n",
    "       a)    Fine-tune number of layers\n",
    "       b)    Number of Neurons in each layers\n",
    "       c)    Experiment in batch-size\n",
    "       d)    Experiment with number of epochs. Check the observations in loss and accuracy\n",
    "       e)    Play with different Learning Rate variants of Gradient Descent like Adam, SGD, RMS-prop\n",
    "       f)    Find out which activation performs best for this use case and why?\n",
    "       g)    Check Confusion Matrix, Precision, Recall and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318431,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 722\n",
      "Trainable params: 722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.add (Dense(15, input_dim = 30, activation = 'relu'))\n",
    "classifier.add (Dense (10, activation = 'relu'))\n",
    "classifier.add (Dense (8, activation = 'relu'))\n",
    "classifier.add (Dense (1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile (loss= 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31844/31844 [==============================] - 37s 1ms/step - loss: 0.0338 - accuracy: 0.9884\n",
      "Epoch 2/10\n",
      "31844/31844 [==============================] - 37s 1ms/step - loss: 0.0107 - accuracy: 0.9972\n",
      "Epoch 3/10\n",
      "31844/31844 [==============================] - 37s 1ms/step - loss: 0.0084 - accuracy: 0.9979\n",
      "Epoch 4/10\n",
      "31844/31844 [==============================] - 37s 1ms/step - loss: 0.0068 - accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "31844/31844 [==============================] - 37s 1ms/step - loss: 0.0060 - accuracy: 0.9986\n",
      "Epoch 6/10\n",
      "31844/31844 [==============================] - 37s 1ms/step - loss: 0.0055 - accuracy: 0.9988\n",
      "Epoch 7/10\n",
      "31844/31844 [==============================] - 37s 1ms/step - loss: 0.0050 - accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "31844/31844 [==============================] - 37s 1ms/step - loss: 0.0047 - accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "31844/31844 [==============================] - 36s 1ms/step - loss: 0.0044 - accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "31844/31844 [==============================] - 37s 1ms/step - loss: 0.0043 - accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14904bda490>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit (x_train, y_train, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICT = [value for pos in predict.tolist() for value in pos]\n",
    "\n",
    "PREDICT_sigmoid = []\n",
    "\n",
    "for value in PREDICT: \n",
    "    if value<0.5: \n",
    "        value = 0   \n",
    "    else: \n",
    "        value=1\n",
    "    PREDICT_sigmoid.append (value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     68376\n",
      "           1       1.00      1.00      1.00     68095\n",
      "\n",
      "    accuracy                           1.00    136471\n",
      "   macro avg       1.00      1.00      1.00    136471\n",
      "weighted avg       1.00      1.00      1.00    136471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test.values.tolist(), PREDICT_sigmoid ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15950/15950 [==============================] - 19s 1ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 2/10\n",
      "15950/15950 [==============================] - 19s 1ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "15950/15950 [==============================] - 19s 1ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 4/10\n",
      "15950/15950 [==============================] - 18s 1ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "15950/15950 [==============================] - 19s 1ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "15950/15950 [==============================] - 19s 1ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 7/10\n",
      "15950/15950 [==============================] - 18s 1ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 8/10\n",
      "15950/15950 [==============================] - 19s 1ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "15950/15950 [==============================] - 19s 1ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "15950/15950 [==============================] - 19s 1ms/step - loss: 0.0019 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1490973b1c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit (x_train_original, y_train_original, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = classifier.predict(x_test_original)\n",
    "\n",
    "PREDICT = [value for pos in predict.tolist() for value in pos]\n",
    "\n",
    "PREDICT_sigmoid = []\n",
    "\n",
    "for value in PREDICT: \n",
    "    if value<0.5: \n",
    "        value = 0   \n",
    "    else: \n",
    "        value=1\n",
    "    PREDICT_sigmoid.append (value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     68236\n",
      "           1       0.87      0.81      0.84       118\n",
      "\n",
      "    accuracy                           1.00     68354\n",
      "   macro avg       0.94      0.91      0.92     68354\n",
      "weighted avg       1.00      1.00      1.00     68354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test_original.values.tolist(), PREDICT_sigmoid ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.    Try out Dropout for ANN. How is it performed? Compare model performance with the traditional\n",
    "#ML based prediction models from above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                30        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,009\n",
      "Trainable params: 1,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.add (Dense(15, input_dim = 30, activation = 'relu'))\n",
    "classifier.add (Dense (10, activation = 'relu') )\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add (Dense (8, activation = 'relu'))\n",
    "classifier.add (Dense (1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile (loss= 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0144 - accuracy: 0.9983\n",
      "Epoch 2/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0047 - accuracy: 0.9988\n",
      "Epoch 3/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "Epoch 4/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 5/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 6/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 7/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 8/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 9/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 10/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 11/20\n",
      "15950/15950 [==============================] - 20s 1ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 12/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 13/20\n",
      "15950/15950 [==============================] - 20s 1ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 14/20\n",
      "15950/15950 [==============================] - 20s 1ms/step - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 15/20\n",
      "15950/15950 [==============================] - 20s 1ms/step - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 16/20\n",
      "15950/15950 [==============================] - 21s 1ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 17/20\n",
      "15950/15950 [==============================] - 20s 1ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 18/20\n",
      "15950/15950 [==============================] - 20s 1ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 19/20\n",
      "15950/15950 [==============================] - 20s 1ms/step - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 20/20\n",
      "15950/15950 [==============================] - 20s 1ms/step - loss: 0.0030 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149098eb070>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit (x_train_original, y_train_original, batch_size = 10, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict = classifier.predict(x_test_original)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICT = [value for pos in predict for value in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "68349    0\n",
       "68350    0\n",
       "68351    0\n",
       "68352    0\n",
       "68353    0\n",
       "Length: 68354, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICT= pd.Series(PREDICT)\n",
    "PREDICT = PREDICT.apply(lambda x: 0 if x<0.5 else 1)\n",
    "PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     68236\n",
      "           1       0.87      0.81      0.84       118\n",
      "\n",
      "    accuracy                           1.00     68354\n",
      "   macro avg       0.94      0.91      0.92     68354\n",
      "weighted avg       1.00      1.00      1.00     68354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test_original.values.tolist(), PREDICT_sigmoid ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    classifier = Sequential ()\n",
    "\n",
    "    classifier.add (Dense(15, input_dim = 30, activation = 'relu'))\n",
    "    classifier.add (Dense (10, activation = 'relu') )\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add (Dense (8, activation = 'relu'))\n",
    "    classifier.add (Dense (1, activation = 'sigmoid'))\n",
    "\n",
    "    classifier.compile (loss= 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "    \n",
    "classifier = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 20, 30]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=3)\n",
    "\n",
    "grid_result = grid.fit(x_train_original, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.999360 using {'batch_size': 60, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly Detection:\n",
    "\n",
    "Implement anomaly detection algorithms. a) Assume that the data is coming from a single or a combination of multivariate Gaussian b) Formalize a scoring criterion, which gives a scoring probability for the given data point whether it belongs to the\n",
    "   multivariate Gaussian or Normal Distribution fitted in a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hkjhjkll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-ea56c33f51ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhkjhjkll\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mkl\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mestimateGaussian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#compute mean of X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msum_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hkjhjkll' is not defined"
     ]
    }
   ],
   "source": [
    "hkjhjkll;kl;n\n",
    "def estimateGaussian(X):\n",
    "    m = x_test.shape[0]\n",
    "    #compute mean of X\n",
    "    sum_ = np.sum(X,axis=0)\n",
    "    mu = (sum_/m)\n",
    "    # compute variance of X\n",
    "    var = np.var(X,axis=0)\n",
    "    print(mu, var)\n",
    "    return mu,var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN \n",
    "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
    "dbscan.fit(x_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "sns.scatterplot(x_train_original, x_train_original, hue=[\"cluster-{}\".format(x) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Task: Week 4\n",
    "\n",
    "Inference and Observations:\n",
    "\n",
    "Visualize the scores for Fraudulent and Non-Fraudulent transactions.\n",
    "Find out the threshold value for marking or reporting a transaction as fraudulent in your anomaly detection system.\n",
    "Can this score be used as an engineered feature in the models developed previously? Are there any incremental gains in F1-Score? Why or Why not?\n",
    "Be as creative as possible in finding other interesting insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
